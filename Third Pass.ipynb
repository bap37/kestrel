{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e50cdf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bpopovic/anaconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dustbi_simulator import *\n",
    "from Functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b1f7740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bpopovic/anaconda3/lib/python3.10/site-packages/pandas/core/arrays/masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"INPUT_DES5YR_D2D.FITRES\", comment=\"#\", sep='\\s+')\n",
    "\n",
    "df['SIM_EBV'] = df.SIM_AV/df.SIM_RV\n",
    "\n",
    "\n",
    "dfdata = pd.read_csv(\"SIMS_FOR_TESTING/FITOPT000.FITRES.gz\", \n",
    "                     comment=\"#\", sep=r'\\s+')\n",
    "\n",
    "#dfdata = pd.read_csv(\"../INVERSE_H0/D5YR_DATA/FITOPT000_MUOPT000.FITRES.gz\", comment=\"#\", sep=r'\\s+')\n",
    "\n",
    "try:\n",
    "    dfdata['SIM_EBV'] = dfdata.SIM_AV/dfdata.SIM_RV\n",
    "except:\n",
    "    print(\"eh.\")\n",
    "\n",
    "dfdata = dfdata.loc[dfdata.IDSURVEY == 10]\n",
    "dfdata = dfdata.loc[dfdata.PROB_SNNV19 >= 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7cbcda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds_dict = {\n",
    "    \"SIM_c\"   : (-0.5, 0.5),\n",
    "    \"SIM_RV\"  : (1.5, 5),\n",
    "    \"SIM_EBV\" : (0,1),\n",
    "    \"SIM_beta\": (0.5,4),\n",
    "}\n",
    "\n",
    "function_dict = {\n",
    "    \"SIM_c\"   : DistGaussian,\n",
    "    \"SIM_RV\"  : DistGaussian,\n",
    "    \"SIM_EBV\" : DistExponential,\n",
    "    \"SIM_beta\": DistGaussian,\n",
    "}\n",
    "\n",
    "split_dict = {\n",
    "#    \"SIM_RV\":[\"HOST_LOGMASS\", 10],\n",
    "    \"SIM_EBV\":['HOST_LOGMASS', 10],\n",
    "    'SIM_c':['HOST_LOGMASS', 10]\n",
    "}\n",
    "\n",
    "\n",
    "#Prior dict is a weird one; it should be a tuple for each parameter and then a boolean statement.\n",
    "\n",
    "split_dict = {}\n",
    "\n",
    "\n",
    "priors_dict = {\n",
    "    \n",
    "    \"SIM_c\"   : [(-0.2, 0), (0.0, 0.1), False],\n",
    "    \"SIM_RV\"  : [(1.5,4), (0,2), True],\n",
    "    \"SIM_EBV\" : [(0.05, 0.3)],\n",
    "    \"SIM_beta\": [(0,3), (0,1), True],\n",
    "    \n",
    "}\n",
    "\n",
    "latex_dict = {\n",
    "    \n",
    "    'DistExponential':[r'$\\tau$'],\n",
    "    'DistGaussian':[r'$\\mu$', r'$\\sigma$'],\n",
    "    'SIM_c':r\"$c_{\\rm int}$\",\n",
    "    'SIM_beta':r\"$\\beta_{\\rm int}$\",\n",
    "    'SIM_RV':r\"$R_V$\",\n",
    "    'SIM_EBV':r\"$EBV$\",\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "dicts = [bounds_dict, function_dict, split_dict, priors_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b479ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bb7bb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total priors added: 7\n",
      "[0] <class 'sbi.utils.torchutils.BoxUniform'>\n",
      "[1] <class 'sbi.utils.torchutils.BoxUniform'>\n",
      "[2] <class 'sbi.utils.torchutils.BoxUniform'>\n",
      "[3] <class 'sbi.utils.torchutils.BoxUniform'>\n",
      "[4] <class 'sbi.utils.torchutils.BoxUniform'>\n",
      "[5] <class 'sbi.utils.torchutils.BoxUniform'>\n",
      "[6] <class 'sbi.utils.torchutils.BoxUniform'>\n"
     ]
    }
   ],
   "source": [
    "param_names = ['SIM_c', 'SIM_RV', 'SIM_beta', 'SIM_EBV']\n",
    "#param_names = ['SIM_c']\n",
    "\n",
    "\n",
    "params_to_fit = parameter_generation(param_names, dicts)\n",
    "priors = prior_generator(param_names, dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "832ae0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = build_layout(params_to_fit, dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d00096f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dae2a03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfb47fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_to_condition_on = ['c', 'mB', 'x1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd6bd37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulatinator = make_simulator(layout, df, param_names, parameters_to_condition_on, dicts, dfdata, is_split=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bef792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "317ecc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim = len(parameters_to_condition_on)\n",
    "\n",
    "if any(p in split_dict for p in param_names): #check early to see if we need to split anything. \n",
    "    ndim *= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf08cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226bf284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b33c4210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched_simulator(theta_batch):\n",
    "    return torch.stack([simulatinator(theta) for theta in theta_batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "289d495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi import analysis as analysis\n",
    "\n",
    "# sbi\n",
    "from sbi import utils as utils\n",
    "from sbi.inference import NPE, simulate_for_sbi\n",
    "from sbi.utils.user_input_checks import (\n",
    "    check_sbi_inputs,\n",
    "    process_prior,\n",
    "    process_simulator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14f68a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check prior, simulator, consistency\n",
    "prior, num_parameters, prior_returns_numpy = process_prior(priors)\n",
    "simulation_wrapper = process_simulator(simulatinator, prior, prior_returns_numpy)\n",
    "check_sbi_inputs(simulation_wrapper, prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d09849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "630f7998",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.inference import SNPE\n",
    "from sbi.utils import MultipleIndependent\n",
    "\n",
    "from sbi.neural_nets import posterior_nn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55e6725",
   "metadata": {},
   "source": [
    "# Potentially Upgraded Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6964b3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PopulationEmbeddingFull(nn.Module):\n",
    "    def __init__(self, input_dim=ndim, hidden_dim=64, output_dim=32):\n",
    "        super().__init__()\n",
    "        self.phi = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.rho = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, N, 2)\n",
    "        h = self.phi(x)           # (batch_size, N, hidden_dim)\n",
    "        h = h.mean(dim=1)         # mean over N samples -> (batch_size, hidden_dim)\n",
    "        return self.rho(h)        # (batch_size, output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3dcf1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.inference import SNPE\n",
    "from sbi.utils import MultipleIndependent\n",
    "\n",
    "from sbi.neural_nets import posterior_nn\n",
    "\n",
    "density_estimator = posterior_nn(\n",
    "    model=\"nsf\", #switch to nsf if interested \n",
    "    embedding_net=PopulationEmbeddingFull(input_dim=4)\n",
    ")\n",
    "\n",
    "inference = SNPE(\n",
    "    prior=priors,\n",
    "    density_estimator=density_estimator, \n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d088d5cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba5a8f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef7644f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Found 8 NaN simulations and 0 Inf simulations. They will be excluded from training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended 100/3000 simulations and saved incrementally.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Found 7 NaN simulations and 0 Inf simulations. They will be excluded from training.\n",
      "/var/folders/2p/hm6bd5n17d5g5kpsm6s7vf3r0002g2/T/ipykernel_87160/4009273070.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(save_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended 200/3000 simulations and saved incrementally.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Found 14 NaN simulations and 0 Inf simulations. They will be excluded from training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended 300/3000 simulations and saved incrementally.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Found 11 NaN simulations and 0 Inf simulations. They will be excluded from training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended 400/3000 simulations and saved incrementally.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "batch_size = 100\n",
    "num_simulations = 3000\n",
    "save_path = \"simulations_v1.pt\"\n",
    "\n",
    "# If the file already exists, start fresh\n",
    "if os.path.exists(save_path):\n",
    "    os.remove(save_path)\n",
    "\n",
    "for start in range(0, num_simulations, batch_size):\n",
    "    current_bs = min(batch_size, num_simulations - start)\n",
    "\n",
    "    # Sample and simulate\n",
    "    theta_batch = priors.sample((current_bs,))\n",
    "    x_batch = batched_simulator(theta_batch)\n",
    "\n",
    "    # Append to SBI inference\n",
    "    inference.append_simulations(theta_batch, x_batch)\n",
    "\n",
    "    # Save incrementally\n",
    "    if start == 0:\n",
    "        # First batch, create the file\n",
    "        torch.save({'theta': theta_batch, 'x': x_batch}, save_path)\n",
    "    else:\n",
    "        # Load existing data\n",
    "        data = torch.load(save_path)\n",
    "        data['theta'] = torch.cat([data['theta'], theta_batch], dim=0)\n",
    "        data['x'] = torch.cat([data['x'], x_batch], dim=0)\n",
    "        torch.save(data, save_path)\n",
    "\n",
    "    print(f\"Appended {start + current_bs}/{num_simulations} simulations and saved incrementally.\")\n",
    "\n",
    "print(f\"All simulations saved incrementally to '{save_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301f743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inference.append_simulations(theta_batch, x_batch)\n",
    "\n",
    "density_estimator = inference.train()\n",
    "\n",
    "print(\"\\n inferred successfully\")\n",
    "\n",
    "posterior = inference.build_posterior(density_estimator)\n",
    "\n",
    "torch.save(posterior, \"posterior.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19603d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962aaf90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe9190d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load(\"simulations_v1.pt\")\n",
    "theta_batch = data[\"theta\"]\n",
    "x_batch = data[\"x\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e599e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28741aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592f5397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f255bb71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b1e1b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc057056",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = preprocess_data(param_names, parameters_to_condition_on, split_dict, dfdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f990af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62efb868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec08dff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436e03fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = unspool_labels(param_names, dicts, latex_dict, function_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab2b2e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "posterior_samples = posterior.sample((50000,), x=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4bd9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = analysis.pairplot(\n",
    "    posterior_samples,\n",
    "    labels=labels\n",
    "\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cac9b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5a4fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a61570d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9718bd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_hat = posterior_samples.mean(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1315aade",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "theta_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3575c33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples.std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ee71d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d34e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(len(theta_hat)):\n",
    "    string = rf\"{labels[n]} = {theta_hat[n]:.3f} +/- {posterior_samples.std(0)[n]:.3f}\"\n",
    "    display(Math(string))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eefdd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_params = torch.tensor([-0.07, 0.53, 2, 0.95, 2.07, 0.22, 0.14,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e413bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulatinator = make_simulator(layout, df, param_names, dicts, dfdata, debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a29f26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = simulatinator(theta_hat)\n",
    "\n",
    "#dft = simulatinator(torch.tensor([[-0.1006,  0.0507,  2.7590,  1.0042,  1.4923,  0.5086,  0.142]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6216ade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3e957a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(-0.4, 0.4, 20)\n",
    "\n",
    "plt.hist(dft.c.values, histtype='step', bins=bins, label=\"sim output\", density=True)\n",
    "plt.hist(dfdata.c.values, histtype='step', bins=bins, label=\"data\", density=True)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33b425f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b2c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(18, 26, 20)\n",
    "\n",
    "plt.hist(dft.mB.values, histtype='step', bins=bins, label=\"sim output\", density=True)\n",
    "plt.hist(dfdata.mB.values, histtype='step', bins=bins, label=\"data\", density=True)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"mB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a411760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 0.6, 20)\n",
    "\n",
    "plt.hist(dft.SIM_EBV.values, histtype='step', bins=bins, label=\"sim output\", density=True)\n",
    "plt.hist(dfdata.SIM_EBV.values, histtype='step', bins=bins, label=\"data\", density=True)\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"E(B-V)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d885c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99a2ad3c",
   "metadata": {},
   "source": [
    "# Calibrate some posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da8c9ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "num_calib = 100  # how many trials for calibration\n",
    "\n",
    "ranks = []\n",
    "\n",
    "for _ in range(num_calib):\n",
    "    # Sample a \"true\" parameter from the prior\n",
    "    theta_true = priors.sample((1,))  # shape (1, num_parameters)\n",
    "\n",
    "    # Simulate data for that theta\n",
    "    x_sim = simulatinator(theta_true)\n",
    "\n",
    "    posterior = inference.build_posterior(density_estimator, sample_with=\"mcmc\")\n",
    "    samples = posterior.sample((200,), x=x_sim)\n",
    "\n",
    "\n",
    "    # Compute rank of true parameter in the posterior samples\n",
    "    for i in range(theta_true.shape[1]):\n",
    "        rank_i = (samples[:, i] < theta_true[0, i]).float().mean()\n",
    "        ranks.append(rank_i.item())\n",
    "\n",
    "# ranks should be ~Uniform[0,1] if well-calibrated\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(ranks, bins=20)\n",
    "plt.xlabel(\"Rank\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"SBC Histogram\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6130819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a534f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flat histogram → well-calibrated.\n",
    "\n",
    "#U-shaped → posteriors too narrow.\n",
    "\n",
    "#Bell-shaped → posteriors too wide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfc8d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a417ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = inference.build_posterior(density_estimator)\n",
    "posterior_samples = posterior.sample((1000,), x=x)\n",
    "\n",
    "# Simulate data from these posterior samples\n",
    "simulated_data = []\n",
    "for theta_s in posterior_samples:\n",
    "    simulated_data.append(simulatinator(theta_s.unsqueeze(0)))\n",
    "\n",
    "simulated_data = torch.cat(simulated_data, dim=0)\n",
    "\n",
    "# Compare histograms of observed vs simulated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad00300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x.numpy().flatten(), bins=30, alpha=0.5, label=\"observed\", density=True)\n",
    "plt.hist(simulated_data.numpy().flatten(), bins=30, alpha=0.5, label=\"posterior predictive\", histtype=\"step\", density=True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd63ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb2dcf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f0d975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aca5207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ae17e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9511f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b308270a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45215d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7c14f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching = [p for p in param_names if p in split_dict]\n",
    "name = matching[0]\n",
    "\n",
    "split_param = split_dict[name][0]\n",
    "split_val   = split_dict[name][1]\n",
    "\n",
    "\n",
    "split_tensor = torch.tensor(\n",
    "dft[split_param].to_numpy(),\n",
    "dtype=torch.float32,\n",
    "device=device\n",
    ")\n",
    "\n",
    "x = split_outputs(\n",
    "    output_distribution,\n",
    "    split_tensor,\n",
    "    split_val,\n",
    "    parameters_to_condition_on\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5effc576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f6f330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb24e967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(param_names, parameters_to_condition_on, split_dict, dfdata, ):\n",
    "    \n",
    "    output_distribution = preprocess_input_distribution(dfdata, parameters_to_condition_on)\n",
    "    \n",
    "    matching = [p for p in param_names if p in split_dict]\n",
    "    name = matching[0]\n",
    "\n",
    "    split_param = split_dict[name][0]\n",
    "    split_val   = split_dict[name][1]\n",
    "\n",
    "    split_tensor = torch.tensor(\n",
    "        df[split_param].to_numpy(),\n",
    "        dtype=torch.float32,\n",
    "        )\n",
    "\n",
    "    x = split_outputs(\n",
    "        output_distribution,\n",
    "        split_tensor,\n",
    "        split_val,\n",
    "        parameters_to_condition_on\n",
    "        )\n",
    "    \n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a740527",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
